#!/usr/bin/env python3
"""
RIFE (Real-Time Intermediate Flow Estimation) ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“
è»½é‡ãƒ»é«˜é€Ÿãªä¸­å‰²ã‚·ã‚¹ãƒ†ãƒ 
"""

import torch
import numpy as np
from PIL import Image
import cv2
from pathlib import Path


class RIFEInterpolator:
    """RIFEè»½é‡ç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“"""
    
    def __init__(self, model_name='rife-v4.6', device='cpu'):
        """
        åˆæœŸåŒ–
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å (rife-v4.6ãŒæœ€æ–°)
            device: 'cpu' or 'cuda'
        """
        self.device = device
        self.model = None
        
    def load_model(self):
        """RIFEãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        print("ğŸ”„ RIFEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # GitHubã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆè»½é‡ï¼‰
        try:
            model = torch.hub.load('megvii-research/ECCV2022-RIFE', 'RIFE', 
                                  device=self.device, force_reload=False)
            self.model = model
            print("âœ“ RIFEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: OpenCVå…‰å­¦ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨")
            self.model = None
            
    def interpolate_opencv(self, img1, img2, num_frames):
        """OpenCVå…‰å­¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹è£œé–“ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        frames = [img1]
        
        gray1 = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2GRAY)
        gray2 = cv2.cvtColor(np.array(img2), cv2.COLOR_RGB2GRAY)
        
        for i in range(1, num_frames - 1):
            alpha = i / (num_frames - 1)
            # å˜ç´”ãªç·šå½¢è£œé–“
            blended = cv2.addWeighted(np.array(img1), 1-alpha, np.array(img2), alpha, 0)
            frames.append(Image.fromarray(blended))
        
        frames.append(img2)
        return frames
    
    def interpolate(self, img1, img2, num_frames=16):
        """
        2æšã®ç”»åƒé–“ã‚’è£œé–“
        
        Args:
            img1: é–‹å§‹ç”»åƒ (PIL Image)
            img2: çµ‚äº†ç”»åƒ (PIL Image)
            num_frames: ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            
        Returns:
            list of PIL Images
        """
        if self.model is None:
            self.load_model()
        
        # RIFEãƒ¢ãƒ‡ãƒ«ãŒä½¿ãˆãªã„å ´åˆã¯OpenCVã‚’ä½¿ç”¨
        if self.model is None:
            print("âš ï¸ RIFEãƒ¢ãƒ‡ãƒ«æœªä½¿ç”¨ã€OpenCVè£œé–“ã‚’å®Ÿè¡Œ")
            return self.interpolate_opencv(img1, img2, num_frames)
        
        # ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        def img2tensor(img):
            img_np = np.array(img).astype(np.float32) / 255.0
            img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0)
            return img_tensor.to(self.device)
        
        I0 = img2tensor(img1)
        I1 = img2tensor(img2)
        
        frames = [img1]
        
        # å†å¸°çš„ã«ä¸­é–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
        print(f"ğŸ¬ {num_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆä¸­...")
        
        with torch.no_grad():
            # æ®µéšçš„ã«è£œé–“
            n_iter = int(np.log2(num_frames - 1))
            
            frame_list = [(0.0, I0), (1.0, I1)]
            
            for iteration in range(n_iter):
                new_frames = []
                for i in range(len(frame_list) - 1):
                    t0, frame0 = frame_list[i]
                    t1, frame1 = frame_list[i + 1]
                    
                    # ä¸­é–“ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
                    mid_frame = self.model(frame0, frame1)
                    t_mid = (t0 + t1) / 2
                    
                    new_frames.append((t0, frame0))
                    new_frames.append((t_mid, mid_frame))
                
                new_frames.append(frame_list[-1])
                frame_list = new_frames
            
            # ãƒ†ãƒ³ã‚½ãƒ«ã‚’PIL Imageã«å¤‰æ›
            for t, frame_tensor in sorted(frame_list, key=lambda x: x[0]):
                if t == 0.0:
                    continue  # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿
                    
                frame_np = frame_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
                frame_np = (frame_np * 255).clip(0, 255).astype(np.uint8)
                frames.append(Image.fromarray(frame_np))
        
        print(f"âœ“ {len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        return frames[:num_frames]  # æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«èª¿æ•´
    
    def save_video(self, frames, output_path, fps=16):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‹•ç”»ã¨ã—ã¦ä¿å­˜"""
        print(f"ğŸ’¾ å‹•ç”»ã‚’ä¿å­˜ä¸­: {output_path}")
        
        if not frames:
            raise ValueError("ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™")
        
        # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚µã‚¤ã‚ºã‚’å–å¾—
        width, height = frames[0].size
        
        # VideoWriterè¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
        
        for frame in frames:
            # PIL Image â†’ OpenCVå½¢å¼
            frame_cv = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)
            out.write(frame_cv)
        
        out.release()
        print(f"âœ“ å‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        return output_path


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='RIFE ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“')
    parser.add_argument('--image1', required=True, help='é–‹å§‹ç”»åƒ')
    parser.add_argument('--image2', required=True, help='çµ‚äº†ç”»åƒ')
    parser.add_argument('--output', default='output_rife.mp4', help='å‡ºåŠ›å‹•ç”»')
    parser.add_argument('--frames', type=int, default=16, help='ãƒ•ãƒ¬ãƒ¼ãƒ æ•°')
    parser.add_argument('--fps', type=int, default=16, help='FPS')
    parser.add_argument('--device', default='cpu', help='cpu or cuda')
    
    args = parser.parse_args()
    
    # ç”»åƒèª­ã¿è¾¼ã¿
    img1 = Image.open(args.image1).convert('RGB')
    img2 = Image.open(args.image2).convert('RGB')
    
    # è£œé–“å®Ÿè¡Œ
    interpolator = RIFEInterpolator(device=args.device)
    frames = interpolator.interpolate(img1, img2, num_frames=args.frames)
    
    # å‹•ç”»ä¿å­˜
    output_path = Path(args.output)
    output_path.parent.mkdir(exist_ok=True, parents=True)
    interpolator.save_video(frames, output_path, fps=args.fps)
    
    print(f"\nâœ… å®Œäº†! {output_path}")


if __name__ == '__main__':
    main()

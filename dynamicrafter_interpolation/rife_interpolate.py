#!/usr/bin/env python3
"""
RIFE (Real-Time Intermediate Flow Estimation) ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“
è»½é‡ãƒ»é«˜é€Ÿãªä¸­å‰²ã‚·ã‚¹ãƒ†ãƒ 
"""

import torch
import numpy as np
from PIL import Image
import cv2
from pathlib import Path


class RIFEInterpolator:
    """RIFEè»½é‡ç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“"""
    
    def __init__(self, model_name='rife-v4.6', device='cpu'):
        """
        åˆæœŸåŒ–
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å (rife-v4.6ãŒæœ€æ–°)
            device: 'cpu' or 'cuda'
        """
        self.device = device
        self.model = None
        
    def apply_motion_transform(self, img, pan_x=0, pan_y=0, zoom=1.0, rotate=0):
        """
        ç”»åƒã«ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å¤‰æ›ã‚’é©ç”¨
        
        Args:
            img: PIL Image
            pan_x: æ°´å¹³ç§»å‹• (-1 to 1, ç”»åƒå¹…ã®å‰²åˆ)
            pan_y: å‚ç›´ç§»å‹• (-1 to 1, ç”»åƒé«˜ã•ã®å‰²åˆ)
            zoom: ã‚ºãƒ¼ãƒ  (0.5 to 2.0)
            rotate: å›è»¢è§’åº¦ (-180 to 180åº¦)
        
        Returns:
            å¤‰æ›å¾Œã®PIL Image
        """
        img_np = np.array(img)
        h, w = img_np.shape[:2]
        
        # å¤‰æ›è¡Œåˆ—ã®æ§‹ç¯‰
        center = (w / 2, h / 2)
        
        # å›è»¢è¡Œåˆ—
        M_rotate = cv2.getRotationMatrix2D(center, rotate, zoom)
        
        # ãƒ‘ãƒ³ï¼ˆå¹³è¡Œç§»å‹•ï¼‰ã‚’è¿½åŠ 
        M_rotate[0, 2] += pan_x * w
        M_rotate[1, 2] += pan_y * h
        
        # å¤‰æ›ã‚’é©ç”¨
        transformed = cv2.warpAffine(img_np, M_rotate, (w, h), 
                                      borderMode=cv2.BORDER_REFLECT)
        
        return Image.fromarray(transformed)
        
    def load_model(self):
        """RIFEãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        print("ğŸ”„ RIFEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # GitHubã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆè»½é‡ï¼‰
        try:
            model = torch.hub.load('megvii-research/ECCV2022-RIFE', 'RIFE', 
                                  device=self.device, force_reload=False)
            self.model = model
            print("âœ“ RIFEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: OpenCVå…‰å­¦ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨")
            self.model = None
            
    def interpolate_opencv(self, img1, img2, num_frames):
        """OpenCVå…‰å­¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹è£œé–“ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        frames = [img1]
        
        gray1 = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2GRAY)
        gray2 = cv2.cvtColor(np.array(img2), cv2.COLOR_RGB2GRAY)
        
        for i in range(1, num_frames - 1):
            alpha = i / (num_frames - 1)
            # å˜ç´”ãªç·šå½¢è£œé–“
            blended = cv2.addWeighted(np.array(img1), 1-alpha, np.array(img2), alpha, 0)
            frames.append(Image.fromarray(blended))
        
        frames.append(img2)
        return frames
    
    def interpolate(self, img1, img2, num_frames=16, mode='basic', 
                   pan_x=0, pan_y=0, zoom=1.0, rotate=0):
        """
        2æšã®ç”»åƒé–“ã‚’è£œé–“
        
        Args:
            img1: é–‹å§‹ç”»åƒ (PIL Image)
            img2: çµ‚äº†ç”»åƒ (PIL Image)
            num_frames: ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            mode: 'basic', 'hybrid', 'steerable'
            pan_x, pan_y: ãƒ‘ãƒ³ç§»å‹• (-1 to 1)
            zoom: ã‚ºãƒ¼ãƒ  (0.5 to 2.0)
            rotate: å›è»¢ (-180 to 180åº¦)
            
        Returns:
            list of PIL Images
        """
        if self.model is None:
            self.load_model()
        
        # RIFEãƒ¢ãƒ‡ãƒ«ãŒä½¿ãˆãªã„å ´åˆã¯OpenCVã‚’ä½¿ç”¨
        if self.model is None:
            print("âš ï¸ RIFEãƒ¢ãƒ‡ãƒ«æœªä½¿ç”¨ã€OpenCVè£œé–“ã‚’å®Ÿè¡Œ")
            return self.interpolate_opencv(img1, img2, num_frames)
        
        # ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ãƒ¢ãƒ¼ãƒ‰
        if mode in ['hybrid', 'steerable']:
            return self.interpolate_with_motion(img1, img2, num_frames, mode,
                                               pan_x, pan_y, zoom, rotate)
        
        # åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰
        return self.interpolate_basic(img1, img2, num_frames)
    
    def interpolate_basic(self, img1, img2, num_frames):
        """åŸºæœ¬çš„ãªRIFEè£œé–“ï¼ˆãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãªã—ï¼‰"""
        # ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        def img2tensor(img):
            img_np = np.array(img).astype(np.float32) / 255.0
            img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0)
            return img_tensor.to(self.device)
        
        I0 = img2tensor(img1)
        I1 = img2tensor(img2)
        
        frames = [img1]
        
        # å†å¸°çš„ã«ä¸­é–“ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
        print(f"ğŸ¬ {num_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆä¸­...")
        
        with torch.no_grad():
            # æ®µéšçš„ã«è£œé–“
            n_iter = int(np.log2(num_frames - 1))
            
            frame_list = [(0.0, I0), (1.0, I1)]
            
            for iteration in range(n_iter):
                new_frames = []
                for i in range(len(frame_list) - 1):
                    t0, frame0 = frame_list[i]
                    t1, frame1 = frame_list[i + 1]
                    
                    # ä¸­é–“ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
                    mid_frame = self.model(frame0, frame1)
                    t_mid = (t0 + t1) / 2
                    
                    new_frames.append((t0, frame0))
                    new_frames.append((t_mid, mid_frame))
                
                new_frames.append(frame_list[-1])
                frame_list = new_frames
            
            # ãƒ†ãƒ³ã‚½ãƒ«ã‚’PIL Imageã«å¤‰æ›
            for t, frame_tensor in sorted(frame_list, key=lambda x: x[0]):
                if t == 0.0:
                    continue  # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿
                    
                frame_np = frame_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
                frame_np = (frame_np * 255).clip(0, 255).astype(np.uint8)
                frames.append(Image.fromarray(frame_np))
        
        print(f"âœ“ {len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        return frames[:num_frames]  # æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«èª¿æ•´
    
    def interpolate_with_motion(self, img1, img2, num_frames, mode,
                               pan_x, pan_y, zoom, rotate):
        """
        ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ä»˜ãè£œé–“
        
        Args:
            mode: 'hybrid' (å…ƒç”»åƒã‚’å¤‰æ›) or 'steerable' (å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¤‰æ›)
        """
        print(f"ğŸ¬ {mode}ãƒ¢ãƒ¼ãƒ‰ã§{num_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆä¸­...")
        print(f"   ãƒ‘ãƒ³: ({pan_x:.2f}, {pan_y:.2f}), ã‚ºãƒ¼ãƒ : {zoom:.2f}, å›è»¢: {rotate}Â°")
        
        if mode == 'hybrid':
            # hybrid: çµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã—ã¦ã‹ã‚‰è£œé–“
            img2_transformed = self.apply_motion_transform(
                img2, pan_x, pan_y, zoom, rotate
            )
            return self.interpolate_basic(img1, img2_transformed, num_frames)
        
        elif mode == 'steerable':
            # steerable: åŸºæœ¬è£œé–“å¾Œã€å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ®µéšçš„ãªãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
            frames_basic = self.interpolate_basic(img1, img2, num_frames)
            frames_motion = []
            
            for i, frame in enumerate(frames_basic):
                # é€²è¡Œåº¦ (0.0 to 1.0)
                progress = i / (len(frames_basic) - 1)
                
                # æ®µéšçš„ã«ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
                frame_transformed = self.apply_motion_transform(
                    frame,
                    pan_x * progress,
                    pan_y * progress,
                    1.0 + (zoom - 1.0) * progress,
                    rotate * progress
                )
                frames_motion.append(frame_transformed)
            
            print(f"âœ“ ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ä»˜ã{len(frames_motion)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ")
            return frames_motion
        
        return []
    
    def save_video(self, frames, output_path, fps=16):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‹•ç”»ã¨ã—ã¦ä¿å­˜"""
        print(f"ğŸ’¾ å‹•ç”»ã‚’ä¿å­˜ä¸­: {output_path}")
        
        if not frames:
            raise ValueError("ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™")
        
        # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚µã‚¤ã‚ºã‚’å–å¾—
        width, height = frames[0].size
        
        # VideoWriterè¨­å®š
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
        
        for frame in frames:
            # PIL Image â†’ OpenCVå½¢å¼
            frame_cv = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)
            out.write(frame_cv)
        
        out.release()
        print(f"âœ“ å‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        return output_path


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='RIFE ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“')
    parser.add_argument('--image1', required=True, help='é–‹å§‹ç”»åƒ')
    parser.add_argument('--image2', required=True, help='çµ‚äº†ç”»åƒ')
    parser.add_argument('--output', default='output_rife.mp4', help='å‡ºåŠ›å‹•ç”»')
    parser.add_argument('--frames', type=int, default=16, help='ãƒ•ãƒ¬ãƒ¼ãƒ æ•°')
    parser.add_argument('--fps', type=int, default=16, help='FPS')
    parser.add_argument('--device', default='cpu', help='cpu or cuda')
    parser.add_argument('--mode', default='basic', choices=['basic', 'hybrid', 'steerable'],
                       help='è£œé–“ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--pan-x', type=float, default=0, help='ãƒ‘ãƒ³ X (-1 to 1)')
    parser.add_argument('--pan-y', type=float, default=0, help='ãƒ‘ãƒ³ Y (-1 to 1)')
    parser.add_argument('--zoom', type=float, default=1.0, help='ã‚ºãƒ¼ãƒ  (0.5 to 2.0)')
    parser.add_argument('--rotate', type=float, default=0, help='å›è»¢ (-180 to 180åº¦)')
    
    args = parser.parse_args()
    
    # ç”»åƒèª­ã¿è¾¼ã¿
    img1 = Image.open(args.image1).convert('RGB')
    img2 = Image.open(args.image2).convert('RGB')
    
    # è£œé–“å®Ÿè¡Œ
    interpolator = RIFEInterpolator(device=args.device)
    frames = interpolator.interpolate(
        img1, img2, 
        num_frames=args.frames,
        mode=args.mode,
        pan_x=args.pan_x,
        pan_y=args.pan_y,
        zoom=args.zoom,
        rotate=args.rotate
    )
    
    # å‹•ç”»ä¿å­˜
    output_path = Path(args.output)
    output_path.parent.mkdir(exist_ok=True, parents=True)
    interpolator.save_video(frames, output_path, fps=args.fps)
    
    print(f"\nâœ… å®Œäº†! {output_path}")


if __name__ == '__main__':
    main()
